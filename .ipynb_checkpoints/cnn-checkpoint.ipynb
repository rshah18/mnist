{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* initialisation - to set the number of input, hidden and output nodes\n",
    "* train - refine the weights after being given a training set example to learn from\n",
    "* query - give an answer from the output nodes after being given an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network class definition\n",
    "class NeuralNet:\n",
    "    \n",
    "    def __init__(self, input_nodes,hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        #number of nodes for input, hidden and output \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        #learning rate\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #matrix of size (hidden_nodes by input_nodes)\n",
    "        # can do (hidden_nodes by input_nodes+1 if bias is included)\n",
    "        #xavier initialization\n",
    "        \n",
    "        self.w_ih = np.random.randn(hidden_nodes, input_nodes)*np.sqrt(1/(input_nodes))\n",
    "        self.w_ho = np.random.randn(output_nodes, hidden_nodes)*np.sqrt(1/(hidden_nodes))\n",
    "        \n",
    "        print('hidden to input weights ',self.w_ih.shape,'\\n\\n', self.w_ih)\n",
    "        print('hidden to output weights ',self.w_ho.shape,'\\n\\n', self.w_ho)\n",
    "        print('\\n\\n')\n",
    "        \n",
    "        self.activate = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "   \n",
    "    #query takes in input and gives out output \n",
    "    # x_hidden = weights_hidden* i \n",
    "    #Ohidden = sigmoid( Xhidden )\n",
    "    \n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        #inputs\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "               \n",
    "        #for hidden layer\n",
    "        hidden_inputs = np.dot(self.w_ih, inputs)\n",
    "        hidden_outputs = self.activate(hidden_inputs)\n",
    "        \n",
    "        #for final layer\n",
    "        final_inputs = np.dot(self.w_ho, hidden_outputs)\n",
    "        final_outputs = self.activate(final_inputs)\n",
    "        \n",
    "        #print('final output ',final_outputs.shape,'\\n\\n',final_outputs)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    def train(self, inlist, tlist):\n",
    "        \n",
    "        #first output is calculated \n",
    "        #second compare the output get difference\n",
    "        #update network weights backwards\n",
    "        \n",
    "        inputs = np.array(inlist, ndmin =2).T\n",
    "        targets = np.array(tlist, ndmin=2).T\n",
    "        \n",
    "        print('inputs ',inputs.shape, '\\n', inputs)\n",
    "        print('targets ',targets.shape,'\\n', targets)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        hidden_inputs = np.dot(self.w_ih, inputs)\n",
    "        hidden_outputs = self.activate(hidden_inputs)\n",
    "        \n",
    "        #print('hidden_inputs w_ih*input ',hidden_inputs.shape,'\\n\\n',hidden_inputs)\n",
    "        #print('hidden_outputs ',hidden_outputs.shape,'\\n\\n', hidden_outputs)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        final_inputs = np.dot(self.w_ho, hidden_outputs)\n",
    "        final_outputs = self.activate(final_inputs)\n",
    "        \n",
    "        #print('''final_input w_ho*hidden_input''',final_inputs.shape,'\\n\\n', final_inputs)\n",
    "        #print('final_output ',final_outputs.shape,'\\n\\n',final_outputs)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        # error = target-final outputs\n",
    "        output_errors = targets-final_outputs\n",
    "        \n",
    "        #print('output_errors target-final_outputs ',output_errors.shape,'\\n\\n',output_errors)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        #hidden_error = weight.T*hidden_output*output_error\n",
    "        hidden_errors = np.dot(self.w_ho.T,output_errors)\n",
    "        \n",
    "        #print('hidden_errors w_ho.T*output_errors', hidden_errors.shape,'\\n\\n',hidden_errors)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        #update weights\n",
    "        #print('output errors', output_errors.shape, '\\n', output_errors, '\\n')\n",
    "        #print('final_outputs',final_outputs.shape, '\\n', final_outputs,'\\n')\n",
    "        #print('1-final_outputs','\\n',1-final_outputs)\n",
    "        #print('hidden_outputs',hidden_outputs.shape,'\\n',hidden_outputs)\n",
    "        #print('hidden_outputs transposed',np.transpose(hidden_outputs))\n",
    "        \n",
    "        self.w_ho += self.lr * np.dot((output_errors *final_outputs*(1.0 - final_outputs)),np.transpose(hidden_outputs))\n",
    "        \n",
    "        #print('self.w_ho',self.w_ho,'\\n\\n',self.w_ho)\n",
    "        #print('\\n\\n')\n",
    "        \n",
    "        #print('self.w_ih',self.w_ih.shape,'\\n\\n',self.w_ih) \n",
    "        \n",
    "        self.w_ih += self.lr * np.dot((hidden_errors * hidden_outputs*(1.0-hidden_inputs)),np.transpose(inputs))\n",
    "        #print('self.w_ih',self.w_ih.shape,'\\n\\n',self.w_ih) \n",
    "        #print('\\n\\n')\n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A matrix for the weights for links between the input and hidden layers, Winput_hidden, of size (hidden_nodes by input_nodes).\n",
    "* A matrix for the links between the hidden and output layers, Wz-hidden_output, of size (output_nodes by hidden_nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "train_dataset = pd.read_csv('/home/ravi/coding/ML/mnist/train.csv')\n",
    "test_dataset = pd.read_csv('//home/ravi/coding/ML/mnist/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_dataset[\"label\"]\n",
    "x = train_dataset.drop(labels = [\"label\"], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden to input weights  (100, 784) \n",
      "\n",
      " [[-0.02305714 -0.03650464  0.01503511 ... -0.00342852  0.04181253\n",
      "  -0.02273393]\n",
      " [-0.03875562  0.02158644  0.01320256 ...  0.04948173 -0.00157295\n",
      "  -0.02882658]\n",
      " [ 0.03924787  0.02234549 -0.02389535 ...  0.04106171  0.0081779\n",
      "   0.00455321]\n",
      " ...\n",
      " [-0.01592538  0.0283362  -0.02401525 ... -0.00416841 -0.01029412\n",
      "  -0.02082092]\n",
      " [-0.01043872  0.03080258 -0.00716001 ...  0.01641945  0.03972367\n",
      "  -0.01527435]\n",
      " [ 0.01876656  0.05851139  0.06830787 ... -0.06710917 -0.00378531\n",
      "  -0.05883826]]\n",
      "hidden to output weights  (10, 100) \n",
      "\n",
      " [[ 1.81801921e-01  2.20349855e-01  3.42073437e-02  1.44000852e-01\n",
      "  -2.06865091e-02  3.50368659e-02 -1.01167520e-01  1.71766666e-02\n",
      "  -1.02634890e-01 -1.56976439e-02 -1.33150024e-01 -3.91728298e-02\n",
      "  -8.69542199e-02  1.74367569e-02  1.62786237e-02 -6.43478789e-02\n",
      "  -4.38100716e-03  5.41936024e-02  5.99702553e-02  2.10517432e-02\n",
      "   3.10543480e-02  9.49119408e-02 -3.30198905e-02 -1.56954412e-02\n",
      "  -5.95227517e-02  6.18575477e-02  1.30613077e-01 -3.61305079e-03\n",
      "   2.19418280e-01 -9.89737923e-02  5.98152119e-02  5.01181042e-02\n",
      "  -2.51301988e-02 -6.20420103e-02  6.04524749e-02 -9.91127743e-02\n",
      "  -6.09575798e-02 -8.67904050e-02  1.82468889e-01 -8.25714717e-02\n",
      "   1.01250780e-01 -1.50487699e-01 -6.82730523e-02  5.79865480e-02\n",
      "  -6.07062721e-02 -4.33393628e-02 -1.15402888e-01 -9.17487686e-02\n",
      "   9.45870943e-03 -3.71090492e-02 -7.82881436e-02 -2.07257337e-02\n",
      "  -1.10491385e-01 -2.88737880e-02 -3.05694201e-02  1.06236089e-01\n",
      "  -1.51975859e-02 -3.00257179e-02 -2.84495969e-02 -1.40700214e-01\n",
      "   1.57943558e-01  1.21679050e-01 -1.93881714e-02 -1.54911021e-01\n",
      "   3.06011682e-02 -7.45522674e-02  1.00983443e-01  2.99518265e-01\n",
      "  -1.90865589e-02 -5.99693436e-02 -4.16612055e-02 -4.26207896e-02\n",
      "   4.95019902e-02  1.80418540e-01  3.26728836e-02  1.30688220e-02\n",
      "   3.04237950e-02 -7.27567156e-02  2.63154626e-02 -1.61994494e-01\n",
      "  -1.58531088e-02  1.73465576e-01  4.53581814e-02 -1.37317772e-01\n",
      "  -1.62482731e-02 -4.46306503e-02 -5.90345576e-02 -1.08176613e-01\n",
      "   9.48186266e-02  7.49116797e-02 -1.41781505e-01 -4.67300580e-02\n",
      "  -1.34680344e-01  8.02885360e-02 -1.71356887e-01 -9.93509898e-02\n",
      "  -7.93175629e-02 -1.09825526e-01 -7.93686815e-02  1.75306063e-02]\n",
      " [ 9.34645293e-02 -1.39034553e-01  9.69681733e-02 -1.80216722e-02\n",
      "  -1.36659763e-02  2.14202764e-01  8.75207313e-03 -1.16947282e-01\n",
      "  -1.42958001e-01 -5.45781862e-02  6.73851565e-03 -1.17306934e-01\n",
      "  -1.37154090e-01  2.19099711e-02 -5.07759467e-02 -4.65651688e-02\n",
      "  -5.21846269e-03  1.29021763e-02 -5.47351734e-02 -6.95162827e-02\n",
      "   1.14672300e-01  8.02476328e-02  4.59980109e-02  4.08363554e-03\n",
      "  -4.90840446e-02 -3.28746441e-02 -6.30836947e-02 -1.01189442e-01\n",
      "   1.45947228e-01 -9.04443625e-02  1.31067174e-02 -1.46050933e-02\n",
      "   5.38456711e-03 -6.31222751e-02  1.74517912e-02  8.98653384e-02\n",
      "  -6.19894904e-02  1.39566190e-01 -1.19305319e-02  1.43432047e-01\n",
      "   1.48070019e-01 -6.29098403e-02  1.23568533e-02 -4.89516375e-02\n",
      "   4.53343342e-02 -6.63465963e-02 -7.51668117e-02  4.18460863e-02\n",
      "   1.16317936e-01  9.70687322e-03 -6.68136538e-02  8.35070169e-02\n",
      "  -3.65719876e-02 -1.91081217e-02 -1.12096871e-01 -1.04108701e-01\n",
      "  -5.63753308e-02 -1.64319083e-01 -1.06806236e-01  1.26020278e-02\n",
      "  -1.17950846e-01  5.95495799e-02 -2.55773350e-01  1.85407809e-01\n",
      "  -2.05581216e-01  1.26397263e-01  2.00782506e-02 -1.03879023e-01\n",
      "  -1.01449324e-01 -2.61002699e-02  4.40295875e-02 -4.73507506e-02\n",
      "   1.09683228e-01 -2.78588350e-02  6.84058155e-02 -1.60690737e-01\n",
      "   1.12272089e-01 -5.82939792e-03 -7.28405963e-02 -2.48947995e-02\n",
      "  -1.17371841e-02  9.44637730e-02  2.74277296e-02  1.32371422e-01\n",
      "  -6.41324197e-02 -5.81324930e-02 -1.49864823e-01 -2.58736685e-02\n",
      "   1.67733252e-01 -2.91439497e-02  3.37388513e-01 -2.09138617e-01\n",
      "  -1.30327771e-01  4.55145304e-02  2.24684211e-01  7.22527775e-02\n",
      "  -2.28112697e-02  1.61654056e-01  8.17799688e-03  4.65220837e-02]\n",
      " [-9.10583526e-02  1.37145252e-01  1.46979906e-01 -2.75576716e-02\n",
      "   1.01285961e-01 -1.34634132e-01  1.56401659e-01  1.43401470e-01\n",
      "  -1.90789226e-01 -1.29790968e-01 -1.17813504e-01 -1.13294908e-02\n",
      "  -8.72188561e-02  6.42924419e-02  5.83464238e-02 -8.35250824e-02\n",
      "   1.47598772e-01 -7.76620096e-02  3.88702944e-02 -5.42529443e-02\n",
      "   5.63046477e-02  3.99400301e-02 -3.27475979e-02 -5.52520763e-02\n",
      "  -1.60659087e-01 -5.84329418e-02 -1.18542486e-01  1.00875750e-01\n",
      "  -1.57020295e-03 -1.79232931e-01  1.28035732e-02 -1.73919536e-01\n",
      "  -3.07029498e-02 -4.63908110e-02 -1.44960126e-01 -1.69009821e-02\n",
      "   5.20041810e-02  2.67108773e-02  1.44921617e-01  4.45616007e-02\n",
      "  -3.99944383e-02 -3.14211159e-02  3.29173896e-02  3.48572170e-02\n",
      "   3.25131279e-02 -3.31575900e-02 -2.81056368e-02  8.47743556e-02\n",
      "   1.72423355e-01  1.47673968e-01  4.25022455e-02  1.61299904e-01\n",
      "  -1.75558477e-02  8.96748286e-02  3.06205713e-02  1.32619011e-01\n",
      "   9.52212115e-02 -2.63687070e-02  3.44419645e-02 -2.48389894e-02\n",
      "   5.87188414e-02 -3.70040297e-03  9.16584093e-02 -1.19454336e-01\n",
      "   8.16380742e-02 -8.75120514e-02  7.41634975e-02 -1.21089391e-01\n",
      "   1.34773277e-01 -1.60115178e-01 -9.19468129e-02  1.76588369e-01\n",
      "  -5.01015531e-02 -1.59996812e-02  7.77329134e-02 -1.27658287e-01\n",
      "   3.96324159e-02 -4.13186406e-02  1.21238393e-01  2.00414776e-02\n",
      "   1.01004232e-01 -6.38195827e-02  6.91713362e-02  2.04119592e-02\n",
      "  -6.57741951e-02 -1.04188926e-01 -8.93773103e-02 -3.25981272e-02\n",
      "  -1.44968491e-01 -6.59544101e-02 -6.13179094e-02 -1.01888865e-01\n",
      "  -3.97466766e-02 -2.88685255e-02  1.24760243e-01  1.13294690e-02\n",
      "   1.10715141e-01  1.40111282e-01  4.62774144e-02  6.41112902e-02]\n",
      " [-9.31804356e-02  1.56982939e-01  7.83769167e-02  1.26422098e-01\n",
      "   2.95704700e-02 -1.13397282e-01  1.32673173e-01  2.00912590e-02\n",
      "   2.72301378e-02  2.08623424e-01 -8.27315286e-02 -3.38113835e-03\n",
      "  -1.71943466e-01  2.01275911e-02  8.22661523e-02  8.11516873e-02\n",
      "  -9.18841661e-02 -2.16162700e-02  1.17577754e-01 -2.86055971e-01\n",
      "   1.47700787e-01  4.45926956e-02  5.77096927e-02  1.04447377e-02\n",
      "   2.37657639e-02  5.05890746e-02  7.16166199e-02 -9.14696299e-02\n",
      "   3.65654309e-02  7.64457321e-02  4.28709864e-02 -1.21448404e-01\n",
      "   2.69805507e-02  1.97903740e-01 -2.65846082e-01 -1.60492465e-02\n",
      "   1.12781707e-01 -1.44206639e-02  2.41110690e-02 -6.45959565e-02\n",
      "  -9.82787315e-02 -5.08345159e-02 -7.50615334e-02  1.80923240e-02\n",
      "   1.59929051e-01  2.42036505e-02 -9.83321736e-02  9.94279525e-02\n",
      "  -6.73801262e-02  4.78850584e-02 -2.64935011e-01  1.23091652e-03\n",
      "  -1.35760098e-01 -1.43910138e-01 -9.55632748e-02 -8.07719214e-02\n",
      "  -9.06783149e-03  9.17381038e-02 -6.04334907e-02  6.03016143e-03\n",
      "  -5.44767073e-04 -7.19460384e-03  1.41041760e-01  1.01610090e-01\n",
      "  -6.97332048e-02  8.59365373e-02 -5.19063022e-03  5.04966005e-03\n",
      "   1.70651841e-02 -5.39882945e-02  1.00196597e-01 -1.20374564e-01\n",
      "  -1.04022858e-01 -5.82343900e-02  2.52125887e-02  1.65437217e-01\n",
      "  -2.19331486e-02 -4.74657637e-02 -1.16641746e-01  7.26444631e-02\n",
      "  -1.00925047e-01  6.37324704e-02 -7.94954234e-02  1.31147572e-02\n",
      "  -8.50393434e-02 -7.29530937e-02 -1.50226169e-01  5.38101158e-02\n",
      "  -1.45049919e-01 -1.32874357e-01  1.39740313e-01 -5.56753354e-02\n",
      "  -1.67915480e-01 -1.03376097e-01 -7.87715726e-02 -2.56353439e-01\n",
      "  -8.16884345e-02 -1.33486805e-01  2.59365921e-02 -8.37257745e-02]\n",
      " [-1.62599331e-01 -5.18735878e-02 -5.45607955e-03  9.29996154e-02\n",
      "   8.20911342e-02  1.41400755e-02  1.90155877e-01  8.78107215e-02\n",
      "   1.66796952e-02 -7.98831685e-02  2.68789552e-02  3.81747267e-04\n",
      "  -7.07552731e-02 -1.44031006e-02 -2.01048475e-02  1.25692294e-01\n",
      "  -4.50662133e-02  1.25167240e-01  2.54457331e-02  1.83223341e-02\n",
      "  -4.33992477e-02 -6.87193439e-02  1.95398414e-01 -4.07458948e-03\n",
      "   9.25141928e-02 -1.06971346e-01  2.58906048e-02  1.02365467e-01\n",
      "   3.54057996e-02  2.23880981e-02  8.30237967e-02  6.07671586e-02\n",
      "   2.26981284e-02  6.45745986e-02  4.02170418e-02 -2.20306664e-02\n",
      "   8.71517118e-02 -1.26757116e-03 -3.54081557e-02  1.10298611e-01\n",
      "  -5.25298059e-02  4.69363874e-02  1.52358050e-02  3.57303189e-02\n",
      "   8.03030837e-02  1.48230932e-02  3.28208939e-03 -4.54251279e-02\n",
      "  -1.07382261e-01 -7.60710427e-02  6.92462724e-02  6.93856732e-02\n",
      "   1.74993339e-01  1.08130376e-01 -1.09757091e-01 -1.15879536e-01\n",
      "  -1.48618817e-03 -8.36443138e-03  1.61008309e-02 -6.13733685e-02\n",
      "   1.85836825e-03 -1.10275741e-01  1.08707876e-02 -2.53190538e-02\n",
      "  -3.32244651e-01  1.83390366e-02 -9.14939700e-02  2.11661371e-02\n",
      "  -1.76511627e-01 -2.34238106e-02 -4.50696358e-02  7.07346058e-02\n",
      "  -2.32594957e-02 -1.56719850e-01 -1.16036471e-01 -2.38671822e-02\n",
      "   4.24650614e-02 -5.52768604e-02 -1.91152855e-01 -9.58221280e-02\n",
      "   2.08875405e-02 -3.87733887e-02 -1.26851844e-01 -1.61913898e-01\n",
      "   5.43297340e-03 -4.88498399e-02  1.56791347e-01  1.10845186e-01\n",
      "   3.24668948e-02  2.67601464e-02  2.01493827e-01 -1.11414958e-01\n",
      "  -3.05354112e-02  1.75064418e-01  1.41328535e-01 -2.72518489e-02\n",
      "   7.67216686e-02  1.37543774e-01  2.67528267e-02 -4.05954412e-02]\n",
      " [ 1.76662588e-01  7.71885678e-02 -6.75851331e-02 -1.07431996e-01\n",
      "  -1.31657543e-01  9.23921467e-02 -1.81130379e-01  1.08763520e-01\n",
      "   7.63165985e-02 -9.92502500e-02 -9.36311624e-02  3.31560135e-02\n",
      "  -2.25260372e-02  1.44145024e-01 -2.50062743e-03  8.70059871e-02\n",
      "  -1.75643595e-01 -1.22395192e-01 -1.31704370e-01  6.42771173e-02\n",
      "   6.82996984e-02 -3.51662723e-02 -9.12494018e-02 -3.39265893e-02\n",
      "   7.08925731e-02  2.33110849e-02  6.54238031e-02  1.24929682e-02\n",
      "  -1.10600400e-01 -1.06114899e-01  1.14417335e-01  8.87393492e-02\n",
      "  -2.29686780e-01  5.22461657e-02  2.35139791e-03 -1.12013729e-01\n",
      "  -8.20268212e-02  2.35075046e-02 -9.37788394e-02  6.39010443e-02\n",
      "  -1.66691917e-01 -3.30928852e-02  3.54749656e-02 -6.06714981e-02\n",
      "  -8.09792265e-02 -1.62444590e-01 -5.73640588e-02 -1.03353611e-01\n",
      "  -3.04947129e-02 -1.35816711e-01 -8.95220830e-02  7.10287983e-02\n",
      "   1.09098661e-01 -1.21651802e-01  1.10767323e-01  1.15277559e-01\n",
      "  -1.55359960e-02 -7.01965449e-02  7.75406571e-03  1.00330006e-01\n",
      "   4.88171378e-02  7.41427643e-02  1.07619213e-01  5.99426951e-02\n",
      "  -1.41273698e-01  1.65722124e-01 -5.54452346e-02  6.62114971e-02\n",
      "   8.64727354e-02  6.70599748e-02 -8.45287158e-02 -1.11843950e-01\n",
      "   4.40864454e-02  6.09473198e-02 -2.43929057e-01 -4.02337890e-02\n",
      "  -1.01865658e-01  6.26944103e-02 -4.03478804e-02 -3.14683548e-02\n",
      "  -2.25630176e-02  1.73504000e-01 -7.58842794e-02  9.56167278e-02\n",
      "  -9.52589297e-02 -4.51781317e-02 -1.36991315e-01 -7.33554603e-02\n",
      "  -1.34191487e-01  8.81787271e-02  1.77031056e-01 -1.38359133e-01\n",
      "   7.38376533e-02  1.24154557e-01 -1.14300147e-01  1.95793211e-01\n",
      "   3.19818403e-02 -1.25529799e-01 -1.02866958e-01  7.76768781e-02]\n",
      " [ 1.87293282e-02  6.56304708e-02 -7.95245652e-02  6.31075646e-02\n",
      "   7.67372224e-02 -1.55553541e-01 -1.04541000e-01 -4.96201727e-02\n",
      "   2.15670172e-01 -1.23469041e-01 -1.16923189e-01  1.27922860e-01\n",
      "  -1.09101870e-01  7.36001054e-02 -9.92748152e-04  4.71697296e-02\n",
      "  -1.43559078e-01  1.91106019e-02  8.79477816e-02 -8.28029218e-03\n",
      "   5.33086476e-02 -6.05425522e-02  1.87668911e-01 -5.45227267e-03\n",
      "  -1.50575418e-02  1.28517215e-01  6.42347254e-02 -3.10228229e-02\n",
      "   1.93794297e-01 -1.26657456e-01 -1.18325115e-02  4.29559156e-02\n",
      "   2.24959693e-01  3.56469656e-02  1.94423254e-02 -5.91465932e-02\n",
      "   7.73499154e-03  1.34721526e-02  1.56967288e-01  1.58092115e-02\n",
      "   8.34304451e-02  6.43893519e-02 -1.36402397e-01 -4.55509003e-02\n",
      "   2.07713678e-01  3.04156875e-04  6.77719665e-02  3.00157375e-02\n",
      "   3.40706161e-02 -3.21302018e-02 -3.67490890e-02  1.41100359e-01\n",
      "  -1.91458406e-01  9.28911656e-02 -5.90655422e-02  7.52234018e-03\n",
      "   1.76432347e-01  1.28383998e-01 -1.35003869e-01 -8.49685475e-02\n",
      "  -7.56553584e-03 -1.46282351e-01  1.26328519e-01  1.66046889e-03\n",
      "  -6.32978987e-02  2.09592719e-01  2.15685656e-02  1.07099867e-01\n",
      "  -4.98236518e-02 -1.47293409e-01 -7.59779668e-02 -7.03726905e-03\n",
      "   1.40542846e-01 -1.08626845e-01  1.75575103e-02  2.13861324e-02\n",
      "   1.24871732e-01 -9.37561310e-03  1.79616589e-02  2.20547112e-01\n",
      "   1.60575945e-01 -2.20896463e-01 -2.13134246e-01 -4.55535583e-02\n",
      "   8.30034116e-02  3.05403629e-02 -2.27277690e-02 -1.72156142e-01\n",
      "  -1.45913690e-02  8.77975159e-02 -2.17306273e-01 -2.94373913e-03\n",
      "  -1.27574294e-01 -7.67771659e-02  1.09127624e-01  1.32399595e-01\n",
      "  -1.44263030e-02 -8.34288434e-02  5.02819887e-02 -1.09120712e-01]\n",
      " [-2.26085517e-01  6.60878895e-02  1.34083310e-02 -5.85517903e-02\n",
      "   9.67370837e-02 -2.85570398e-02 -4.39769869e-02  4.56979945e-02\n",
      "  -4.89133329e-02  1.20459177e-01  9.79029432e-02 -1.94541244e-01\n",
      "   3.87270479e-03 -8.74049679e-02  1.39408795e-01  2.29163477e-03\n",
      "  -6.03085416e-02 -1.68450635e-01 -8.21852083e-02  1.12796747e-01\n",
      "   6.11373342e-02 -8.36245757e-02  1.28007112e-01 -1.35608264e-02\n",
      "   2.64750765e-02 -1.31073331e-01 -4.35972823e-02  1.28920087e-01\n",
      "  -1.33507792e-01  1.25583073e-01  1.40103273e-01  2.90780996e-02\n",
      "  -7.48480676e-02  2.73459509e-02  2.30485736e-01  2.35117356e-02\n",
      "  -1.98695656e-01  2.85562442e-02  1.17044227e-01  1.04445131e-01\n",
      "   7.18342120e-02 -7.68324253e-02 -3.71144884e-02 -1.93707534e-02\n",
      "  -1.75584057e-02  1.32047191e-01 -4.19701291e-02 -9.04274223e-02\n",
      "   2.04060249e-02  7.66957133e-03  1.06272982e-01  1.70658027e-01\n",
      "  -1.83997486e-02  8.71701565e-02 -1.36859924e-01 -5.27799863e-02\n",
      "   3.76026950e-02 -8.20415002e-03  5.73224751e-02  9.96910994e-02\n",
      "  -7.35805263e-02 -3.78294700e-02 -2.33382723e-01 -2.82830243e-03\n",
      "   5.52342715e-02 -7.31121127e-03  3.26499772e-02  4.06549755e-02\n",
      "   1.02397352e-01  3.50362092e-02 -5.57683221e-02 -1.77139381e-01\n",
      "   5.10427354e-02 -2.15122754e-01  8.72483820e-02  6.27557151e-02\n",
      "  -5.14757585e-04  1.70579767e-01  2.61922238e-02  2.39649651e-02\n",
      "   5.98964686e-03  6.29737880e-02  3.75542117e-02  9.61678735e-02\n",
      "  -1.10059929e-01  8.97134897e-02  1.27246665e-01 -3.08520526e-02\n",
      "  -1.61319507e-01  8.98630491e-02  9.76877414e-02  1.38446479e-01\n",
      "  -2.26520835e-01 -4.90062888e-02 -1.00465161e-01 -6.25923411e-02\n",
      "   5.23094512e-02 -1.28798027e-01  3.26316300e-02  7.22927644e-02]\n",
      " [ 6.39798435e-02  3.46694812e-02  1.17827189e-01  8.94828291e-02\n",
      "   6.33377449e-03 -5.57113727e-02  1.03347978e-01 -5.97454190e-02\n",
      "  -3.29094772e-02 -3.54820769e-02  6.55349739e-02  3.70256880e-02\n",
      "   1.68896512e-01 -2.07967173e-01  4.40055060e-02  1.09390671e-01\n",
      "  -5.32888441e-02  3.72010684e-02 -6.33342272e-03  7.98701830e-02\n",
      "  -1.11737460e-01  2.05562087e-02  1.34793156e-01  1.52770514e-02\n",
      "   9.12636671e-02 -2.21068726e-01  7.77845120e-03  9.57094684e-03\n",
      "  -5.53560467e-02 -1.02252330e-02  2.44790775e-02 -3.63826737e-02\n",
      "  -2.13030991e-02 -2.36651241e-02 -1.72868603e-01  7.96759659e-02\n",
      "  -1.57123279e-01 -6.29736104e-02  1.66685198e-01 -1.96363491e-01\n",
      "  -1.05814306e-01 -1.67962644e-01 -7.04033104e-03 -2.85744588e-02\n",
      "   1.33691859e-01 -1.55151860e-03  3.90610588e-02  1.40068684e-01\n",
      "   5.49956156e-02 -2.03231882e-02  1.97104759e-01 -9.26653932e-02\n",
      "   1.56823956e-02 -2.74853103e-02 -4.05830152e-02 -7.81168113e-02\n",
      "   4.11319486e-02 -1.23002965e-01 -1.43247031e-01  1.25106115e-02\n",
      "   2.23753450e-02  1.84473545e-03 -1.44291685e-01  1.84641074e-01\n",
      "  -2.80515282e-02 -1.67445366e-01  8.87607789e-02 -1.30776344e-01\n",
      "   6.42414104e-02 -1.38329840e-01  1.28056701e-01  2.67525687e-02\n",
      "   1.97454320e-01  1.08118090e-01 -2.98754991e-04  4.56018918e-02\n",
      "  -1.47450969e-01 -1.50543833e-01  3.22847029e-02  7.84829480e-02\n",
      "   7.71764122e-02  2.49608150e-01 -5.71852824e-02  4.61906965e-02\n",
      "   1.33380985e-01  4.32900892e-02 -4.21467981e-02 -5.71742195e-03\n",
      "  -6.49370183e-02  1.11493693e-01 -1.66129185e-01 -2.50325031e-01\n",
      "   1.16259908e-01 -1.23867053e-01 -6.83758540e-02  7.19535130e-02\n",
      "  -2.09972200e-02 -2.07212152e-02 -5.23837255e-02 -1.65341635e-01]\n",
      " [-1.27650288e-01  1.44699292e-01  8.20836580e-02  1.15013230e-01\n",
      "  -1.72314800e-01 -3.68171407e-02 -1.06285785e-02 -1.52381722e-01\n",
      "  -7.37711030e-02 -1.44008956e-01 -1.07199209e-02  9.96073531e-02\n",
      "  -1.76535399e-01 -6.38381955e-02 -1.70503477e-01 -3.45462014e-02\n",
      "   2.27593306e-02  1.15269074e-01  7.13908400e-02  5.29785832e-02\n",
      "  -1.64844771e-02 -4.25146783e-02 -1.96576108e-01 -4.16313132e-02\n",
      "  -1.03479191e-01  2.15730259e-02  1.36401188e-01 -4.31025804e-02\n",
      "  -2.02844838e-01 -4.70271469e-02 -1.52897255e-01 -3.69651833e-02\n",
      "   1.64094756e-02  3.13735353e-01 -1.00188086e-01 -2.69902431e-01\n",
      "  -4.35451457e-02  5.21783051e-02 -1.18379795e-01  3.45029879e-03\n",
      "   3.00292791e-02 -1.51065986e-01  3.48994574e-01  6.21738134e-02\n",
      "  -1.92642136e-01  2.24370115e-02  6.98870060e-02  1.93445510e-01\n",
      "  -5.03214762e-02 -7.01421640e-02 -1.75545153e-01  1.21115559e-01\n",
      "  -2.73565680e-01 -2.39564318e-02 -5.17023665e-02  3.47157458e-02\n",
      "   7.65014079e-02  4.70036830e-02 -7.74769939e-02  2.57871522e-02\n",
      "   8.48332599e-02  1.78478176e-01  5.60750347e-02  2.01175405e-02\n",
      "   1.36684164e-01 -8.92172731e-03  4.64054390e-02 -1.21513447e-01\n",
      "   1.17620331e-01 -1.12662687e-01 -7.61835787e-02  3.44950560e-03\n",
      "   1.09469078e-01 -1.62482775e-03 -9.38939597e-02  1.77988191e-01\n",
      "  -1.31059835e-01 -8.57653362e-02 -1.40660971e-01 -1.46185897e-01\n",
      "  -3.67186277e-02 -6.57250517e-02 -3.15909796e-02 -4.85863975e-02\n",
      "  -1.76496080e-02  1.02410085e-01 -6.21632414e-04 -1.93575252e-01\n",
      "  -1.38802873e-01  8.93323942e-02  2.80326193e-02  1.58713799e-01\n",
      "  -1.04835982e-01 -2.65915416e-02 -2.48447194e-01  2.02621974e-01\n",
      "  -7.95206796e-02  6.74088245e-03 -3.27753213e-02 -1.26051532e-02]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNet(784, 100, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff3f2884828>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x[5].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target array has all 0 elements except for the one which it is which has highest value \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "for i in range(0,42000):\n",
    "    real = np.zeros(10)\n",
    "    real[y[i]]=0.99\n",
    "    target.append(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure output is same as output array length and input to input \n",
    "target.shape, x.shape\n",
    "\n",
    "# to avoid overflow when multiplying the array we scale the inputs \n",
    "x = ((x/255.0) * 0.99) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 9.838095238095237 sample:  0 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  1 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  2 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  3 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  4 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  5 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  6 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  7 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  8 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  9 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  10 epoch:  0\n",
      "accuracy: 9.838095238095237 sample:  11 epoch:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d4125dc3ec12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0masd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mabss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training with samples and error rate \n",
    "\n",
    "for i in range(0,3):\n",
    "    for j in range(0,420):\n",
    "        nn.train(x[j],target[j])\n",
    "        score = []\n",
    "        for r in range(0,42000):\n",
    "            asd = nn.query(x[r])\n",
    "            abss = asd.tolist()\n",
    "            rank = abss.index(max(abss))\n",
    "            if rank == y[r]:\n",
    "                score.append(1)\n",
    "            else:\n",
    "                score.append(0)\n",
    "                \n",
    "        accuracy = sum(score)/len(score)*100\n",
    "        print('accuracy:', accuracy, 'sample: ',j, 'epoch: ', i)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x[590].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ade= [1,0,1,0,1,0]\n",
    "sum(ade)/len(ade)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 1\n",
      "0 [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 0\n",
      "0 [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 1\n",
      "0 [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 4\n",
      "0 [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] 0\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "for r in range(0,5):\n",
    "    asd = nn.query(x[r])\n",
    "    abss = asd.tolist()\n",
    "    rank = abss.index(max(abss))\n",
    "    if rank == y[r]:\n",
    "        score.append(1)\n",
    "    else:\n",
    "        score.append(0)\n",
    "    print(rank,asd, y[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
